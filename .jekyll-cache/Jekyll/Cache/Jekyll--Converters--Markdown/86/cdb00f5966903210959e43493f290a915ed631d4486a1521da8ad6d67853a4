I"!<h3 id="abstract">Abstract</h3>
<p>Emotions are integral to the social media user experience; we express our feelings, react to posted content and communicate with emoji. This may lead to emotional contagion and undesirable behaviors such as cyberbullying and flaming. Nearly real-time negative emotion detection during the use of social media could mitigate these behaviors, but existing techniques rely on corpora of aggregated user-generated data - posted comments or social graph structure. This paper explores how live data extracted from smartphone sensors can predict binary affect, valence and arousal during the typical social media tasks of browsing content and chatting. Results show that momentary emotion can be predicted, using features from screen touches and device motions, with peak F1-scores of 0.86, 0.86, 0.88 for affect, valence and arousal.
<br />
<br /></p>

<h3 id="more-info">More Info</h3>
<p>This work was led by <a href="https://mintra-ruensuk.github.io/">Mintra Ruensuk</a>, a PhD candidate at UNIST. The outcome of this work has been published to ASIAN-CHI in 2019. Check out details in <a href="https://mintra-ruensuk.github.io/asian-chi/">Mintraâ€™s portfolio</a>.
<br />
<br /></p>

<h3 id="image-credit">Image Credit</h3>
<p>Photo by Erik Lucatero on Unsplash
<br />
<br /></p>
:ET